{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501ce78c-fbb7-48ae-a7f1-e0a699ee771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import pdfplumber\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6484364-912b-4843-bd63-ce03d960e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correct PDF Link: https://www.bvmt.com.tn/sites/default/files/indices/sectoriels/composition_tunindex20.pdf\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Access the initial page\n",
    "initial_page_url = \"https://www.bvmt.com.tn/fr/compositions/TN0009050287/details\"\n",
    "response = requests.get(initial_page_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 2: Find all links and search for a .pdf link\n",
    "pdf_link_tag = None\n",
    "\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if \".pdf\" in link['href']:\n",
    "        pdf_link_tag = link\n",
    "        break  # Stop at the first PDF link found\n",
    "\n",
    "# Step 3: Extract and format the PDF link\n",
    "if pdf_link_tag:\n",
    "    pdf_url = pdf_link_tag['href']\n",
    "\n",
    "    # Ensure the link is complete\n",
    "    if not pdf_url.startswith(\"http\"):\n",
    "        pdf_url = \"https://www.bvmt.com.tn\" + pdf_url\n",
    "\n",
    "    print(f\"✅ Correct PDF Link: {pdf_url}\")\n",
    "else:\n",
    "    print(\"❌ No PDF link found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5858c90-afb9-48e7-8569-979e6112c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF downloaded successfully: pdf\\composition_tunindex20.pdf\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where the PDF will be saved\n",
    "pdf_directory = \"pdf\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(pdf_directory, exist_ok=True)\n",
    "\n",
    "# Define the local filename with the path\n",
    "pdf_filename = os.path.join(pdf_directory, \"composition_tunindex20.pdf\")\n",
    "\n",
    "# Download the PDF\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "# Save the file in Colab's environment\n",
    "with open(pdf_filename, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"✅ PDF downloaded successfully: {pdf_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cec7e4-53a3-492a-bc05-835eeb2f593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV files saved in the 'csv' folder.\n"
     ]
    }
   ],
   "source": [
    "# Charger les fichiers CSV\n",
    "df_repartition_A = pd.read_csv(\"csv/repartition_A.csv\")\n",
    "df_repartition_B = pd.read_csv(\"csv/repartition_B.csv\")\n",
    "\n",
    "# Fusionner les deux fichiers en supprimant les doublons\n",
    "df_repartition = pd.concat([df_repartition_A, df_repartition_B]).drop_duplicates()\n",
    "\n",
    "# Filtrer les entreprises en fonction du groupe de cotation\n",
    "df_continu = df_repartition[df_repartition[\"GROUPE DE COTATION\"].str.contains(\"Continu\", na=False)]\n",
    "df_fixing = df_repartition[df_repartition[\"GROUPE DE COTATION\"].str.contains(\"Fixing\", na=False)]\n",
    "\n",
    "# Define the directory where the CSV files will be saved\n",
    "csv_directory = \"csv\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(csv_directory, exist_ok=True)\n",
    "\n",
    "# Define file paths\n",
    "continu_csv_path = os.path.join(csv_directory, \"continu.csv\")\n",
    "fixing_csv_path = os.path.join(csv_directory, \"fixing.csv\")\n",
    "\n",
    "# Save the CSV files in the \"csv\" folder\n",
    "df_continu.to_csv(continu_csv_path, index=False, encoding=\"utf-8\")\n",
    "df_fixing.to_csv(fixing_csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ CSV files saved in the '{csv_directory}' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ba68c6-9315-41e8-b04f-0f8793debed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Columns: ['N°', 'ISIN CODE', 'MNEMO', 'COMPANY NAME', 'NUMBER OF SHARES', 'FREE FLOAT', 'CAPPING COEFFICIENT']\n",
      "CSV file with Liquidity column saved: csv\\composition_tunindex20.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_table_with_liquidity(pdf_path, csv_output_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        tables = []\n",
    "        \n",
    "        # Extract tables from all pages\n",
    "        for page in pdf.pages:\n",
    "            extracted_tables = page.extract_tables()\n",
    "            for table in extracted_tables:\n",
    "                tables.append(table)\n",
    "\n",
    "    # Flatten and normalize the extracted tables\n",
    "    if tables:\n",
    "        all_data = []\n",
    "        for table in tables:\n",
    "            for row in table:\n",
    "                all_data.append(row)\n",
    "        \n",
    "        # Convert to DataFrame and clean data\n",
    "        df = pd.DataFrame(all_data)\n",
    "\n",
    "        # Remove empty rows\n",
    "        df = df.dropna(how='all')  \n",
    "\n",
    "        # Ensure first row is header and clean column names\n",
    "        df.columns = df.iloc[0]  # Set first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row from data\n",
    "\n",
    "        # Remove newlines & extra spaces from headers\n",
    "        df.columns = df.columns.str.replace(r\"[\\n\\r]+\", \" \", regex=True).str.strip()\n",
    "\n",
    "        # Remove text before and including '/' (for multi-line headers)\n",
    "        df.columns = df.columns.str.replace(r\".*/\\s*\", \"\", regex=True)\n",
    "\n",
    "        # Debugging: Print extracted columns\n",
    "        print(\"Extracted Columns:\", df.columns.tolist())\n",
    "\n",
    "        # **Remove rows that contain non-numeric values in 'NUMBER OF SHARES'**\n",
    "        df = df[df[\"NUMBER OF SHARES\"].str.replace(\" \", \"\", regex=True).str.isnumeric()]\n",
    "\n",
    "        # Convert numeric columns correctly\n",
    "        df[\"NUMBER OF SHARES\"] = df[\"NUMBER OF SHARES\"].str.replace(\" \", \"\", regex=True).astype(float)\n",
    "        df[\"FREE FLOAT\"] = df[\"FREE FLOAT\"].str.rstrip('%').astype(float) / 100\n",
    "\n",
    "        # Calculate Liquidity\n",
    "        df[\"LIQUIDITY\"] = df[\"NUMBER OF SHARES\"] * df[\"FREE FLOAT\"]\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(csv_output_path, index=False, encoding='utf-8')\n",
    "        print(f\"CSV file with Liquidity column saved: {csv_output_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No tables found in the PDF.\")\n",
    "\n",
    "# **Example usage**\n",
    "pdf_path = \"pdf/composition_tunindex20.pdf\"  # Replace with your actual PDF file\n",
    "# Define the directory where the CSV file will be saved\n",
    "csv_directory = \"csv\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(csv_directory, exist_ok=True)\n",
    "\n",
    "# Define the file path within the \"csv\" folder\n",
    "csv_output_path = os.path.join(csv_directory, \"composition_tunindex20.csv\")\n",
    "extract_table_with_liquidity(pdf_path, csv_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29ac9c-02ab-4a32-be7b-2851870bffbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
