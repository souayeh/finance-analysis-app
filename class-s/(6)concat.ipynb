{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da05824-afcf-4a16-8c09-2c11c828b629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated file with COMPARTIMENT column saved to: csv/end.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths and their corresponding compartiments\n",
    "file_paths = {\n",
    "    \"csv/repartition_A.csv\": \"A\",\n",
    "    \"csv/repartition_B.csv\": \"B\",\n",
    "    \"csv/repartition_S.csv\": \"S\"\n",
    "}\n",
    "\n",
    "# Load and concatenate data while adding the \"COMPARTIMENT\" column\n",
    "df_list = []\n",
    "for file, compartiment in file_paths.items():\n",
    "    temp_df = pd.read_csv(file)\n",
    "    temp_df[\"COMPARTIMENT\"] = compartiment  # Assign compartiment\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "end_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Ensure the column name \"MNEMO\" is correct in both datasets\n",
    "mnemo_column = \"MNEMO\"  # Change if needed\n",
    "\n",
    "# Load composition data\n",
    "composition_df = pd.read_csv(\"csv/composition_tunindex20.csv\")\n",
    "\n",
    "# Create a set of mnemo values from composition_tunindex20.csv\n",
    "mnemo_set = set(composition_df[mnemo_column])\n",
    "\n",
    "# Add the tunindex20 column based on the condition\n",
    "end_df[\"TUNINDEX20\"] = end_df[mnemo_column].isin(mnemo_set)\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "output_file = \"csv/end.csv\"\n",
    "end_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Concatenated file with COMPARTIMENT column saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c06abc-d1c0-44aa-9bc4-2e2607169540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "crx_df = pd.read_csv(\"csv/crx.csv\")\n",
    "companies_sectors_df = pd.read_csv(\"csv/companies_sectors.csv\")\n",
    "\n",
    "# Ensure column names are correct\n",
    "best_match_column = \"BEST MATCH\"  # Change this if the actual column name is different\n",
    "company_column = \"COMPANY\"\n",
    "valeur_column = \"VALEUR\"\n",
    "\n",
    "# Create a mapping from \"best match\" to \"company\"\n",
    "best_match_to_company = dict(zip(crx_df[best_match_column], crx_df[company_column]))\n",
    "\n",
    "# Replace \"valeur\" in companies_sectors_df where it matches \"best match\"\n",
    "companies_sectors_df[valeur_column] = companies_sectors_df[valeur_column].replace(best_match_to_company)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "output_file = \"csv/companies_sectors.csv\"\n",
    "companies_sectors_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32cd59f2-68a6-48ac-8b67-7e29e21dfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_df = pd.read_csv(\"csv/end.csv\")\n",
    "companies_sectors_df = pd.read_csv(\"csv/companies_sectors.csv\")\n",
    "\n",
    "# Ensure column names are correct\n",
    "valeur_column = \"VALEUR\"\n",
    "sector_column = \"SECTOR\"\n",
    "\n",
    "# Merge the two datasets based on \"valeur\"\n",
    "end_df = end_df.merge(companies_sectors_df[[valeur_column, sector_column]], on=valeur_column, how=\"left\")\n",
    "\n",
    "# Save the updated DataFrame\n",
    "output_file = \"csv/end.csv\"\n",
    "end_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0ea0d1-2443-4afb-a09d-dfda5025d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end_df = pd.read_csv(\"csv/end.csv\")  # Assuming you want to use the updated file\n",
    "\n",
    "# List of Sharia-compliant stocks\n",
    "SHARIA_COMPLIANT_STOCKS = [\n",
    "    \"ICF\", \"DELICE HOLDING\", \"TELNET HOLDING\", \"EURO-CYCLES\",\n",
    "    \"SIAME\", \"SAH\", \"SMART TUNISIE\", \"SOTIPAPIER\", \"UNIMED\",\n",
    "    \"SOTUVER\", \"ARTES\", \"STA\", \"BEST LEASE\", \"WIFACK INT BANK\"\n",
    "]\n",
    "\n",
    "# Add the \"sharia\" column\n",
    "end_df[\"SHAARIA\"] = end_df[\"VALEUR\"].isin(SHARIA_COMPLIANT_STOCKS)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "output_file = \"csv/end.csv\"\n",
    "end_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f030a6-6955-4691-b7c1-3760693df461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
